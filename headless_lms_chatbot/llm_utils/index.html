<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="generator" content="rustdoc"><meta name="description" content="API documentation for the Rust `llm_utils` mod in crate `headless_lms_chatbot`."><title>headless_lms_chatbot::llm_utils - Rust</title><script>if(window.location.protocol!=="file:")document.head.insertAdjacentHTML("beforeend","SourceSerif4-Regular-6b053e98.ttf.woff2,FiraSans-Regular-0fe48ade.woff2,FiraSans-Medium-e1aa3f0a.woff2,SourceCodePro-Regular-8badfe75.ttf.woff2,SourceCodePro-Semibold-aa29a496.ttf.woff2".split(",").map(f=>`<link rel="preload" as="font" type="font/woff2" crossorigin href="../../static.files/${f}">`).join(""))</script><link rel="stylesheet" href="../../static.files/normalize-9960930a.css"><link rel="stylesheet" href="../../static.files/rustdoc-42caa33d.css"><meta name="rustdoc-vars" data-root-path="../../" data-static-root-path="../../static.files/" data-current-crate="headless_lms_chatbot" data-themes="" data-resource-suffix="" data-rustdoc-version="1.84.1 (e71f9a9a9 2025-01-27)" data-channel="1.84.1" data-search-js="search-92e6798f.js" data-settings-js="settings-0f613d39.js" ><script src="../../static.files/storage-59e33391.js"></script><script defer src="../sidebar-items.js"></script><script defer src="../../static.files/main-5f194d8c.js"></script><noscript><link rel="stylesheet" href="../../static.files/noscript-893ab5e7.css"></noscript><link rel="alternate icon" type="image/png" href="../../static.files/favicon-32x32-6580c154.png"><link rel="icon" type="image/svg+xml" href="../../static.files/favicon-044be391.svg"></head><body class="rustdoc mod"><!--[if lte IE 11]><div class="warning">This old browser is unsupported and will most likely display funky things.</div><![endif]--><nav class="mobile-topbar"><button class="sidebar-menu-toggle" title="show sidebar"></button></nav><nav class="sidebar"><div class="sidebar-crate"><h2><a href="../../headless_lms_chatbot/index.html">headless_<wbr>lms_<wbr>chatbot</a><span class="version">0.1.0</span></h2></div><div class="sidebar-elems"><section id="rustdoc-toc"><h2 class="location"><a href="#">Module llm_<wbr>utils</a></h2><h3><a href="#structs">Module Items</a></h3><ul class="block"><li><a href="#structs" title="Structs">Structs</a></li><li><a href="#enums" title="Enums">Enums</a></li><li><a href="#constants" title="Constants">Constants</a></li><li><a href="#functions" title="Functions">Functions</a></li></ul></section><div id="rustdoc-modnav"><h2 class="in-crate"><a href="../index.html">In crate headless_<wbr>lms_<wbr>chatbot</a></h2></div></div></nav><div class="sidebar-resizer"></div><main><div class="width-limiter"><rustdoc-search></rustdoc-search><section id="main-content" class="content"><div class="main-heading"><span class="rustdoc-breadcrumbs"><a href="../index.html">headless_lms_chatbot</a></span><h1>Module <span>llm_utils</span><button id="copy-path" title="Copy item path to clipboard">Copy item path</button></h1><rustdoc-toolbar></rustdoc-toolbar><span class="sub-heading"><a class="src" href="../../src/headless_lms_chatbot/llm_utils.rs.html#1-325">Source</a> </span></div><h2 id="structs" class="section-header">Structs<a href="#structs" class="anchor">Â§</a></h2><ul class="item-table"><li><div class="item-name"><a class="struct" href="struct.AzureCompletionRequest.html" title="struct headless_lms_chatbot::llm_utils::AzureCompletionRequest">Azure<wbr>Completion<wbr>Request</a></div><div class="desc docblock-short">Simple completion-focused LLM request for Azure OpenAI
Note: In Azure OpenAI, the model is specified in the URL, not in the request body</div></li><li><div class="item-name"><a class="struct" href="struct.BaseLlmRequest.html" title="struct headless_lms_chatbot::llm_utils::BaseLlmRequest">Base<wbr>LlmRequest</a></div><div class="desc docblock-short">Base LLM request structure (common fields)</div></li><li><div class="item-name"><a class="struct" href="struct.LlmChoice.html" title="struct headless_lms_chatbot::llm_utils::LlmChoice">LlmChoice</a></div></li><li><div class="item-name"><a class="struct" href="struct.LlmCompletionResponse.html" title="struct headless_lms_chatbot::llm_utils::LlmCompletionResponse">LlmCompletion<wbr>Response</a></div><div class="desc docblock-short">Response from LLM for simple completions</div></li><li><div class="item-name"><a class="struct" href="struct.Message.html" title="struct headless_lms_chatbot::llm_utils::Message">Message</a></div><div class="desc docblock-short">Common message structure used for LLM requests</div></li></ul><h2 id="enums" class="section-header">Enums<a href="#enums" class="anchor">Â§</a></h2><ul class="item-table"><li><div class="item-name"><a class="enum" href="enum.MessageRole.html" title="enum headless_lms_chatbot::llm_utils::MessageRole">Message<wbr>Role</a></div><div class="desc docblock-short">Role of a message in a conversation</div></li></ul><h2 id="constants" class="section-header">Constants<a href="#constants" class="anchor">Â§</a></h2><ul class="item-table"><li><div class="item-name"><a class="constant" href="constant.LLM_API_VERSION.html" title="constant headless_lms_chatbot::llm_utils::LLM_API_VERSION">LLM_<wbr>API_<wbr>VERSION</a></div></li></ul><h2 id="functions" class="section-header">Functions<a href="#functions" class="anchor">Â§</a></h2><ul class="item-table"><li><div class="item-name"><a class="fn" href="fn.build_llm_headers.html" title="fn headless_lms_chatbot::llm_utils::build_llm_headers">build_<wbr>llm_<wbr>headers</a></div><div class="desc docblock-short">Builds common headers for LLM requests</div></li><li><div class="item-name"><a class="fn" href="fn.estimate_tokens.html" title="fn headless_lms_chatbot::llm_utils::estimate_tokens">estimate_<wbr>tokens</a></div><div class="desc docblock-short">Estimate the number of tokens in a given text.</div></li><li><div class="item-name"><a class="fn" href="fn.make_blocking_llm_request.html" title="fn headless_lms_chatbot::llm_utils::make_blocking_llm_request">make_<wbr>blocking_<wbr>llm_<wbr>request</a></div><div class="desc docblock-short">Makes a non-streaming request to an LLM using application configuration</div></li><li><div class="item-name"><a class="fn" href="fn.make_llm_request.html" title="fn headless_lms_chatbot::llm_utils::make_llm_request">make_<wbr>llm_<wbr>request</a><span title="Restricted Visibility">&nbsp;ðŸ”’</span> </div><div class="desc docblock-short">Makes a non-streaming request to an LLM</div></li><li><div class="item-name"><a class="fn" href="fn.make_streaming_llm_request.html" title="fn headless_lms_chatbot::llm_utils::make_streaming_llm_request">make_<wbr>streaming_<wbr>llm_<wbr>request</a></div><div class="desc docblock-short">Makes a streaming request to an LLM</div></li><li><div class="item-name"><a class="fn" href="fn.prepare_azure_endpoint.html" title="fn headless_lms_chatbot::llm_utils::prepare_azure_endpoint">prepare_<wbr>azure_<wbr>endpoint</a></div><div class="desc docblock-short">Prepares Azure OpenAI endpoint with API version</div></li><li><div class="item-name"><a class="fn" href="fn.process_llm_response.html" title="fn headless_lms_chatbot::llm_utils::process_llm_response">process_<wbr>llm_<wbr>response</a><span title="Restricted Visibility">&nbsp;ðŸ”’</span> </div><div class="desc docblock-short">Process a non-streaming LLM response</div></li></ul></section></div></main></body></html>